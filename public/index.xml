<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Peder M. Isager on Peder M. Isager</title>
    <link>/</link>
    <description>Recent content in Peder M. Isager on Peder M. Isager</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0200</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>How to share your data online with OSF</title>
      <link>/post/how-to-share-your-data-with-osf/</link>
      <pubDate>Tue, 02 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-share-your-data-with-osf/</guid>
      <description>&lt;div id=&#34;disclaimer&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;strong&gt;Disclaimer:&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;In the time I spent writing up this blog post, &lt;a href=&#34;https://twitter.com/cksoderberg&#34;&gt;Courtney Soderberg&lt;/a&gt; published &lt;a href=&#34;https://doi.org/10.1177%2F2515245918757689&#34;&gt;a tutorial manuscript for data sharing on OSF&lt;/a&gt; in the journal AMPPS. I highly recommend checking it out!&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;intro&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Intro&lt;/h4&gt;
&lt;p&gt;The Open Science movement is here to stay. Journals, reviewers, and fellow scientists increasingly expect that data and materials from research findings be made available upon publication. There are very good reasons for this, as open data and materials have the potential to increase reproducibility and collaboration, reduce the cost of data collection, and shift the focus from single findings to cumulative research programs. I think every researcher will stand to benefit from these uptakes in open practices. However, it is one thing to preach open science, and antother to practice it.&lt;/p&gt;
&lt;p&gt;If you have never made data available online before, it might all seem a bit daunting. Where should I put the data? What should I put up? What do I need to consider before I do it? Fortunately, making data available online does not need to be be very difficult. There are a few things you should know before posting your data online, but if you learn how to do it once, the procedure is overall quite similar from dataset to dataset. The time investement is well worth it in my experience. Katherine Wood has already written &lt;a href=&#34;https://katherinemwood.github.io/post/data_sharing_tips/&#34;&gt;an excellent blog post&lt;/a&gt; with general tips and advice on sharing data and analysis scripts. So exellent in fact, that you should just read it, and come back afterwards. See you soon!&lt;/p&gt;
&lt;p&gt;…&lt;/p&gt;
&lt;p&gt;Welcome back! Now that you know what you should think about when making your data and analysis scripts open, let me walk you through a practical example of how you can do this on The Open Science Frameword (OSF). This is just one of many platforms for data sharing you could consider, but OSF’s flexibility and general user friendliness makes it a good place to start.&lt;/p&gt;
&lt;p&gt;OSF is a website maintained by the Center for Open Science, and is a hub for everything Open Science. OSF will store your data &lt;em&gt;for free&lt;/em&gt;, and they have a back-up fund in case they run out of money, guaranteeing that your data will be accessible for at least 50 years. In other words, you get a free back-up of your data, and you can die happy, knowing that your data will live on long after you are gone. On that cheerful note, let’s get started!&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/OSF_how_to/OSF_frontpage.png&#34; alt=&#34;Figure 1: OSF Frontpage.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; OSF Frontpage.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;create-a-profile&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Create a profile&lt;/h4&gt;
&lt;p&gt;First, you need to head over to OSF and create a profile. As mentioned, this is completely free. On the front page, click the green “Sign up” button, fill in your personal details, and you should be good to go.&lt;/p&gt;
&lt;p&gt;When you are signed up and logged in, you should find yourself on the OSF dashboard. OSF keeps data and materials sorted into “projects”, and on the home screen you get an overview of your projects. In the upper right corner you will find a taskbar. If you click your name and then click “My Profile” in the drop-down menu, you can see and add information about yourself such as social media accounts, your ORCID ID, etc. To get back to the dashboard from anywhere, click the “OSF &lt;strong&gt;HOME&lt;/strong&gt;” button on the upper left of the page. Now let’s create a project and see how we can add data to it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;create-a-new-project&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Create a new project&lt;/h4&gt;
&lt;p&gt;When on the dashboard page, click the green “Create new project” button. This will open a dialogue box prompting you to fill in the name of the project. Try to write a sensible name that describes the content of the project (I.e. not “Data”). A good solution is to use the title of the paper/manuscript/grant proposal that is connected to the data you want to share. You will also be prompted to choose at which location you would prefer your data to be stored. If you are an EU researcher, choose “Germany - frankfurt” as your storage location to make your data &lt;a href=&#34;https://www.insight.mrc.ac.uk/2018/04/16/gdpr-research-changes/&#34;&gt;GDPR&lt;/a&gt; compliant. Check out &lt;a href=&#34;http://help.osf.io/m/settings/l/952786-set-a-global-storage-location&#34;&gt;this link&lt;/a&gt; to learn how to change the default storage location for all your future projects. You can also click “more” below the title box, and add a description (you can edit this later as well). When done, click “create”, and click “Go to new project” in the following dialogue box.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/OSF_how_to/new_project_dialogue.png&#34; alt=&#34;Figure 2: Dialogue box for creating new project.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; Dialogue box for creating new project.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Welcome to your new project! You should now be looking at your brand new project page! On this page you can add all the files and information relevant to your project/study. Notice immediately that your project is currently private (fig 3.1). This means that only you have access to this project and its contents. You can add collaborators in privat mode (like a shared folder on Dropbox), but the project and its content will not be &lt;em&gt;publicly&lt;/em&gt; available until you decide to make it so. If all you want is a way of sharing data with collaborators, you can even choose to &lt;em&gt;never&lt;/em&gt; make the project public. If you do make it public, also note the citation box (fig 3.2). You, or anyone visiting your project, can click the arrow in the far right corner of the box and get a dropdown box of citations in different style formats. In addition to this, public projects can also get a DOI (Once you make a project public, a “Create DOI/ARKID” link appears about 5 lines below the project name). This makes it easy for you to cite your project in a manuscript or CV, and for others to cite your project in their publications.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/OSF_how_to/OSF_project_page_reference_image2.png&#34; alt=&#34;Figure 3: OSF project page. Numbers are referenced in text as fig 3.[1-10].&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;&lt;strong&gt;Figure 3:&lt;/strong&gt; OSF project page. Numbers are referenced in text as “fig 3.[1-10]”.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;set-up-and-navigate-the-project-page&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Set up and navigate the project page&lt;/h4&gt;
&lt;p&gt;Now let’s give people a reason to cite this project! Here is a step by step by step guide for setting up your project in a way that makes it easy for people to find and use the information you want to share.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Add a description of your project (fig 3.3). If you have already written a manuscript on the data, you could just click this field and paste the abstract. In any case, the description should make it clear what the project is intended for, and what kind of information one can expect to find here.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add a license for your project (fig 3.4). Having a liberal license for your data is more important than you may think. If you share materials without a license, people are not strictly allowed to reuse it (without risking legal prosecution from you). You can find more information about licensing your data &lt;a href=&#34;https://wiki.creativecommons.org/wiki/Data&#34;&gt;here&lt;/a&gt;. If you just want to get on with it however, click “add a license”, and in the “&lt;strong&gt;Choose a license:&lt;/strong&gt;” drop-down menu, choose either the &lt;a href=&#34;https://creativecommons.org/publicdomain/zero/1.0/&#34;&gt;CC0 1.0 Universal&lt;/a&gt; or the &lt;a href=&#34;https://creativecommons.org/licenses/by/4.0/&#34;&gt;CC By Attribution 4.0 International&lt;/a&gt;. They are both aimed at making your data open and reducable by others with minimal legal restrictions. If you want to know more about why licensing is important, or you want to know the difference between the CC licenses, &lt;a href=&#34;https://twitter.com/chartgerink&#34;&gt;Chris Hartgerink&lt;/a&gt; has written &lt;a href=&#34;https://medium.com/read-write-participate/copyright-and-licenses-in-open-access-publishing-da73e0ca8ed3&#34;&gt;a short, informative, and accessible article on Medium&lt;/a&gt; about it.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Before uploading, make sure that people can understand and work with the materials you upload. This implies the following:
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Name the variables in your dataset sensibly, and perhaps add a document that defines and describes each variable (a &lt;a href=&#34;http://www.ddialliance.org/training/getting-started-new-content/create-a-codebook&#34;&gt;codebook&lt;/a&gt;). In addition, adding extra materials, such as experiment presentation files, design descriptions, etc., can be a crucial supplement to the methods section of your paper for someone who really wants to understand how the experiment was conducted.&lt;/li&gt;
&lt;li&gt;Provide a complete recipe script for any published analyses in case someone wants to doublecheck your reporting. In SPSS, this is made in a syntax (.sps) file. In R, this is made in an R script (.R) file. The script should start by importing/loading the raw (anonymized) data, then include every manipulation imposed on the data (like deletions, renamings, and exclusions), and end with the functions for generating the plots running the statistical tests that you report. In other words, a person who downloads your data and analysis files should just have to press play in the appropriate software to reproduce the numbers in your paper. If you can’t add raw data for ethical reasons, add a dataset as close to the raw as possible. Why? Imagine you made a mistake in renaming a variable, or someone disagrees with your exclusion critera. If someone then wants to change the way the data is manipulated, they will need access to the pre-manipulation version of the dataset.&lt;/li&gt;
&lt;li&gt;Make sure that accessing your data is free, or as cheap as possible. If you use SPSS for data analysis, something you might never think about is the fact that all the files you save in .sav, .spv, and .sps format requires SPSS to open them. So anyone who wants to reuse your data will need SPSS as well, and that baby costs $99 per month! Same goes for matlab ($580-$2300 per license), e-prime ($995 per license) and other common commercial research software. A &lt;a href=&#34;https://www.computerhope.com/issues/ch001357.htm&#34;&gt;.csv&lt;/a&gt; version of your dataset can be read and created by basically any program, so &lt;a href=&#34;https://www.computerhope.com/issues/ch001356.htm&#34;&gt;create one&lt;/a&gt; and add it just in case.&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Upload your data and materials! This is as simple as dragging and dropping the files into the “Files” box (fig 3.5). You can also click on “OSF Storage” (fig 3.6) and click on the “upload” button that appears above. If you want to import data directly from services like Dropbox, Google Drive, or GitHub, you will find a list of add-ons you can integrate by going to Settings (fig 3.7).&lt;/li&gt;
&lt;li&gt;Add some relevant tags (fig 3.8) to make your project easy to find on Google and OSF search.&lt;/li&gt;
&lt;li&gt;If you want to add some information about the project, consider putting it into the project Wiki (fig 3.9). Detailed info on how to edit the wiki can be found &lt;a href=&#34;http://help.osf.io/m/collaborating/l/524109-using-the-wiki&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Let the public in! If you are happy with the content, settings, and information included in your project (and you want to make it public), press the “Make Public” button (fig 3.10). Read through the warnings that pops up and, if you are sure that your project meets ethical requirements for open data sharing, click “Confirm”.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;finding-help-and-more-information&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Finding help and more information&lt;/h4&gt;
&lt;p&gt;Did you run into any trouble along the way? Fear not! Reliable sources tell me that OSF also has a very real and friendly human person you can reach at &lt;a href=&#34;mailto:support@osf.io&#34;&gt;support@osf.io&lt;/a&gt;, who would be happy to help you out.&lt;/p&gt;
&lt;p&gt;No more trouble? Then congratulations! You now have an open, licensed, reuasable, and citable version of your data and materials that can be accessed by anyone for the forseeable future. Just put a link to the project in your manuscript and voilà! Anyone can make use of your openly shared data, at no extra cost to you! &lt;/p&gt;
&lt;p&gt;&lt;em&gt;PS: If you want to see an example of any of the recommendations offered here, check out &lt;a href=&#34;https://osf.io/r2gbv/&#34;&gt;the OSF project for this post&lt;/a&gt; where I tried to address them all. You can also find a lot more information and help on the &lt;a href=&#34;https://osf.io/support/&#34;&gt;OSF support pages&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;PPSS: If you are interested in learning more about how to increase the transparency of your research practices, check out this &lt;a href=&#34;http://doi.org/10.1525/collabra.158&#34;&gt;detailed practical guide to transparency in psychological science&lt;/a&gt;, by Klein et al.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to share your data online with OSF</title>
      <link>/post/how-to-share-your-data-with-osf/</link>
      <pubDate>Tue, 02 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-share-your-data-with-osf/</guid>
      <description>

&lt;p&gt;####&lt;strong&gt;Disclaimer:&lt;/strong&gt;
&lt;em&gt;In the time I spent writing up this blog post, &lt;a href=&#34;https://twitter.com/cksoderberg&#34; target=&#34;_blank&#34;&gt;Courtney Soderberg&lt;/a&gt; published &lt;a href=&#34;https://doi.org/10.1177%2F2515245918757689&#34; target=&#34;_blank&#34;&gt;a tutorial manuscript for data sharing on OSF&lt;/a&gt; in the journal AMPPS. I highly recommend checking it out!&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;intro&#34;&gt;Intro&lt;/h4&gt;

&lt;p&gt;The Open Science movement is here to stay. Journals, reviewers, and fellow scientists increasingly expect that data and materials from research findings be made available upon publication. There are very good reasons for this, as open data and materials have the potential to increase reproducibility and collaboration, reduce the cost of data collection, and shift the focus from single findings to cumulative research programs. I think every researcher will stand to benefit from these uptakes in open practices. However, it is one thing to preach open science, and antother to practice it.&lt;/p&gt;

&lt;p&gt;If you have never made data available online before, it might all seem a bit daunting. Where should I put the data? What should I put up? What do I need to consider before I do it? Fortunately, making data available online does not need to be be very difficult. There are a few things you should know before posting your data online, but if you learn how to do it once, the procedure is overall quite similar from dataset to dataset. The time investement is well worth it in my experience. Katherine Wood has already written &lt;a href=&#34;https://katherinemwood.github.io/post/data_sharing_tips/&#34; target=&#34;_blank&#34;&gt;an excellent blog post&lt;/a&gt; with general tips and advice on sharing data and analysis scripts. So exellent in fact, that you should just read it, and come back afterwards. See you soon!&lt;/p&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;p&gt;Welcome back! Now that you know what you should think about when making your data and analysis scripts open, let me walk you through a practical example of how you can do this on The Open Science Frameword (OSF). This is just one of many platforms for data sharing you could consider, but OSF&amp;rsquo;s flexibility and general user friendliness makes it a good place to start.&lt;/p&gt;

&lt;p&gt;OSF is a website maintained by the Center for Open Science, and is a hub for everything Open Science. OSF will store your data &lt;em&gt;for free&lt;/em&gt;, and they have a back-up fund in case they run out of money, guaranteeing that your data will be accessible for at least 50 years. In other words, you get a free back-up of your data, and you can die happy, knowing that your data will live on long after you are gone. On that cheerful note, let&amp;rsquo;s get started!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/OSF_how_to/OSF_frontpage.png&#34; alt=&#34;**Figure 1:** OSF Frontpage.&#34; /&gt;&lt;/p&gt;

&lt;p&gt;####Create a profile&lt;/p&gt;

&lt;p&gt;First, you need to head over to OSF and create a profile. As mentioned, this is completely free. On the front page, click the green &amp;ldquo;Sign up&amp;rdquo; button, fill in your personal details, and you should be good to go.&lt;/p&gt;

&lt;p&gt;When you are signed up and logged in, you should find yourself on the OSF dashboard. OSF keeps data and materials sorted into &amp;ldquo;projects&amp;rdquo;, and on the home screen you get an overview of your projects. In the upper right corner you will find a taskbar. If you click your name and then click &amp;ldquo;My Profile&amp;rdquo; in the drop-down menu, you can see and add information about yourself such as social media accounts, your ORCID ID, etc. To get back to the dashboard from anywhere, click the &amp;ldquo;OSF &lt;strong&gt;HOME&lt;/strong&gt;&amp;rdquo; button on the upper left of the page. Now let&amp;rsquo;s create a project and see how we can add data to it.&lt;/p&gt;

&lt;p&gt;####Create a new project&lt;/p&gt;

&lt;p&gt;When on the dashboard page, click the green &amp;ldquo;Create new project&amp;rdquo; button. This will open a dialogue box prompting you to fill in the name of the project. Try to write a sensible name that describes the content of the project (I.e. not &amp;ldquo;Data&amp;rdquo;). A good solution is to use the title of the paper/manuscript/grant proposal that is connected to the data you want to share. You will also be prompted to choose at which location you would prefer your data to be stored. If you are an EU researcher, choose &amp;ldquo;Germany - frankfurt&amp;rdquo; as your storage location to make your data &lt;a href=&#34;https://www.insight.mrc.ac.uk/2018/04/16/gdpr-research-changes/&#34; target=&#34;_blank&#34;&gt;GDPR&lt;/a&gt; compliant. Check out &lt;a href=&#34;http://help.osf.io/m/settings/l/952786-set-a-global-storage-location&#34; target=&#34;_blank&#34;&gt;this link&lt;/a&gt; to learn how to change the default storage location for all your future projects. You can also click &amp;ldquo;more&amp;rdquo; below the title box, and add a description (you can edit this later as well). When done, click &amp;ldquo;create&amp;rdquo;, and click &amp;ldquo;Go to new project&amp;rdquo; in the following dialogue box.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/OSF_how_to/new_project_dialogue.png&#34; alt=&#34;**Figure 2:** Dialogue box for creating new project.&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Welcome to your new project! You should now be looking at your brand new project page! On this page you can add all the files and information relevant to your project/study. Notice immediately that your project is currently private (fig 3.1). This means that only you have access to this project and its contents. You can add collaborators in privat mode (like a shared folder on Dropbox), but the project and its content will not be &lt;em&gt;publicly&lt;/em&gt; available until you decide to make it so. If all you want is a way of sharing data with collaborators, you can even choose to &lt;em&gt;never&lt;/em&gt; make the project public. If you do make it public, also note the citation box (fig 3.2). You, or anyone visiting your project, can click the arrow in the far right corner of the box and get a dropdown box of citations in different style formats. In addition to this, public projects can also get a DOI (Once you make a project public, a &amp;ldquo;Create DOI/ARKID&amp;rdquo; link appears about 5 lines below the project name). This makes it easy for you to cite your project in a manuscript or CV, and for others to cite your project in their publications.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/OSF_how_to/OSF_project_page_reference_image2.png&#34; alt=&#34;**Figure 3:** OSF project page. Numbers are referenced in text as &amp;quot;fig 3.[1-10]&amp;quot;.&#34; /&gt;&lt;/p&gt;

&lt;p&gt;####Set up and navigate the project page&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s give people a reason to cite this project! Here is a step by step by step guide for setting up your project in a way that makes it easy for people to find and use the information you want to share.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Add a description of your project (fig 3.3). If you have already written a manuscript on the data, you could just click this field and paste the abstract. In any case, the description should make it clear what the project is intended for, and what kind of information one can expect to find here.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Add a license for your project (fig 3.4).  Having a liberal license for your data is more important than you may think. If you share materials without a license, people are not strictly allowed to reuse it (without risking legal prosecution from you). You can find more information about licensing your data &lt;a href=&#34;https://wiki.creativecommons.org/wiki/Data&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. If you just want to get on with it however, click &amp;ldquo;add a license&amp;rdquo;, and in the &amp;ldquo;&lt;strong&gt;Choose a license:&lt;/strong&gt;&amp;rdquo; drop-down menu, choose either the &lt;a href=&#34;https://creativecommons.org/publicdomain/zero/1.0/&#34; target=&#34;_blank&#34;&gt;CC0 1.0 Universal&lt;/a&gt; or the &lt;a href=&#34;https://creativecommons.org/licenses/by/4.0/&#34; target=&#34;_blank&#34;&gt;CC By Attribution 4.0 International&lt;/a&gt;. They are both aimed at making your data open and reducable by others with minimal legal restrictions. If you want to know more about why licensing is important, or you want to know the difference between the CC licenses, &lt;a href=&#34;https://twitter.com/chartgerink&#34; target=&#34;_blank&#34;&gt;Chris Hartgerink&lt;/a&gt; has written &lt;a href=&#34;https://medium.com/read-write-participate/copyright-and-licenses-in-open-access-publishing-da73e0ca8ed3&#34; target=&#34;_blank&#34;&gt;a short, informative, and accessible article on Medium&lt;/a&gt; about it.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Before uploading, make sure that people can understand and work with the materials you upload. This implies the following:
a. Name the variables in your dataset sensibly, and perhaps add a document that defines and describes each variable (a &lt;a href=&#34;http://www.ddialliance.org/training/getting-started-new-content/create-a-codebook&#34; target=&#34;_blank&#34;&gt;codebook&lt;/a&gt;). In addition, adding extra materials, such as experiment presentation files, design descriptions, etc., can be a crucial supplement to the methods section of your paper for someone who really wants to understand how the experiment was conducted.
a. Provide a complete recipe script for any published analyses in case someone wants to doublecheck your reporting. In SPSS, this is made in a syntax (.sps) file. In R, this is made in an R script (.R) file. The script should start by importing/loading the raw (anonymized) data, then include every manipulation imposed on the data (like deletions, renamings, and exclusions), and end with the functions for generating the plots running the statistical tests that you report. In other words, a person who downloads your data and analysis files should just have to press play in the appropriate software to reproduce the numbers in your paper. If you can&amp;rsquo;t add raw data for ethical reasons, add a dataset as close to the raw as possible. Why? Imagine you made a mistake in renaming a variable, or someone disagrees with your exclusion critera. If someone then wants to change the way the data is manipulated, they will need access to the pre-manipulation version of the dataset.
a. Make sure that accessing your data is free, or as cheap as possible. If you use SPSS for data analysis, something you might never think about is the fact that all the files you save in .sav, .spv, and .sps format requires SPSS to open them. So anyone who wants to reuse your data will need SPSS as well, and that baby costs \$99 per month! Same goes for matlab (\$580-\$2300 per license), e-prime (\$995 per license) and other common commercial research software. A &lt;a href=&#34;https://www.computerhope.com/issues/ch001357.htm&#34; target=&#34;_blank&#34;&gt;.csv&lt;/a&gt; version of your dataset can be read and created by basically any program, so &lt;a href=&#34;https://www.computerhope.com/issues/ch001356.htm&#34; target=&#34;_blank&#34;&gt;create one&lt;/a&gt; and add it just in case.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Upload your data and materials! This is as simple as dragging and dropping the files into the &amp;ldquo;Files&amp;rdquo; box (fig 3.5). You can also click on &amp;ldquo;OSF Storage&amp;rdquo; (fig 3.6) and click on the &amp;ldquo;upload&amp;rdquo; button that appears above. If you want to import data directly from services like Dropbox, Google Drive, or GitHub, you will find a list of add-ons you can integrate by going to Settings (fig 3.7).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Add some relevant tags (fig 3.8) to make your project easy to find on Google and OSF search.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;If you want to add some information about the project, consider putting it into the project Wiki (fig 3.9). Detailed info on how to edit the wiki can be found &lt;a href=&#34;http://help.osf.io/m/collaborating/l/524109-using-the-wiki&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Let the public in! If you are happy with the content, settings, and information included in your project (and you want to make it public), press the &amp;ldquo;Make Public&amp;rdquo; button (fig 3.10). Read through the warnings that pops up and, if you are sure that your project meets ethical requirements for open data sharing, click &amp;ldquo;Confirm&amp;rdquo;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;####Finding help and more information&lt;/p&gt;

&lt;p&gt;Did you run into any trouble along the way? Fear not! Reliable sources tell me that OSF also has a very real and friendly human person you can reach at support@osf.io, who would be happy to help you out.&lt;/p&gt;

&lt;p&gt;No more trouble? Then congratulations! You now have an open, licensed, reuasable, and citable version of your data and materials that can be accessed by anyone for the forseeable future. Just put a link to the project in your manuscript and voilà! Anyone can make use of your openly shared data, at no extra cost to you!
\newline
\newline&lt;/p&gt;

&lt;p&gt;&lt;em&gt;PS: If you want to see an example of any of the recommendations offered here, check out &lt;a href=&#34;https://osf.io/r2gbv/&#34; target=&#34;_blank&#34;&gt;the OSF project for this post&lt;/a&gt; where I tried to address them all. You can also find a lot more information and help on the &lt;a href=&#34;https://osf.io/support/&#34; target=&#34;_blank&#34;&gt;OSF support pages&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;PPSS: If you are interested in learning more about how to increase the transparency of your research practices, check out this &lt;a href=&#34;http://doi.org/10.1525/collabra.158&#34; target=&#34;_blank&#34;&gt;detailed practical guide to transparency in psychological science&lt;/a&gt;, by Klein et al.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ganging Up on Psychological Science</title>
      <link>/post/ganging-up-on-psych-science/</link>
      <pubDate>Fri, 31 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/ganging-up-on-psych-science/</guid>
      <description>&lt;div id=&#34;everything-is-awesome.-everything-is-cool-when-youre-part-of-a-team.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Everything is awesome. Everything is cool when you’re part of a team.&lt;/h2&gt;
&lt;p&gt;&lt;br/&gt; The idea of having heaps of scientists come together to accomplish something none of them could do on their own is not new. Take &lt;a href=&#34;https://home.cern/&#34;&gt;CERN&lt;/a&gt;, established in 1954 and one of the most famous large scale collaborations in science to date. CERN is a massive experimental undertaking with a mission to address fundamental problems in physics. Today, it employs over 2500 scientists from 22 countries and has lead to some pretty impressive innovations, like the construction of the Large Hadron Collider (the world’s biggest machine), the discovery of the Higgs boson, and the invention of the Word Wide Web.&lt;/p&gt;
&lt;p&gt;The utility of large scale collaborations in psychology is much the same as in physics. Sometimes, the costs of doing good science outgrows the resources available to the individual researcher. In physics, this might be the money and manpower required to build machinery necessary for empirical observation. For example, the Large Hadron Collider experiments has an expected price-tag of around 5.5 billion USD &lt;span class=&#34;citation&#34;&gt;(“Large Hadron Collider” 2018)&lt;/span&gt;. In psychology, large scale collaboration has the potential to help us muster the organizational resources required to collect sufficiently large and diverse (non-WEIRD) samples from the human population. It can also can mitigate subpar research practices caused by individual knowledge gaps by bringing together multiple researchers with a wide variety of skills and expertise.&lt;/p&gt;
&lt;p&gt;Large scale collaborations are already beginning to impact psychology in important ways. For example, a summary of the 100 replication studies included in the “Reproducibility Project: Psychology” was published in Science &lt;span class=&#34;citation&#34;&gt;(Open Science Collaboration 2015)&lt;/span&gt;, and the project has helped elevate the status of replication research in psychology ever since. The idea of reproducibility projects has also spread to neighbouring areas, and similar collaborative undertakings can now be found in experimental economics &lt;span class=&#34;citation&#34;&gt;(Camerer et al. 2016)&lt;/span&gt;, cancer biology &lt;span class=&#34;citation&#34;&gt;(“Effort to Reproduce Cancer Studies Scales down to 18 Papers,” n.d.)&lt;/span&gt;, experimental philosophy &lt;span class=&#34;citation&#34;&gt;(Cova et al. 2018)&lt;/span&gt;, and social science research published in Science and Nature &lt;span class=&#34;citation&#34;&gt;(Camerer et al. 2018)&lt;/span&gt;. Other established collaborations include the “Many Labs” projects, which have published authoritative reports on the role of contextual effects in psychological research, including the infamous end-of-semester effect &lt;span class=&#34;citation&#34;&gt;(Ebersole et al. 2016)&lt;/span&gt;. The “Many Babies” project &lt;span class=&#34;citation&#34;&gt;(“The ManyBabies Project,” n.d.)&lt;/span&gt; is studying thousands of infants in an attempt to address some big questions in developmental psychology. To illustrate how do these collaborations function and how they help us do good science, let me describe the one I am a member of in a little more detail.&lt;/p&gt;
&lt;p&gt;In August 2017, Dr. Christopher R. Chartier published a &lt;a href=&#34;https://christopherchartier.com/2017/08/26/building-a-cern-for-psychological-science/&#34;&gt;blog post&lt;/a&gt; outlining a new kind of collaboration project within psychology. Inspired by the structure of CERN, this would be a standing network of volunteer labs from all across the world that would work together on huge and distributed data collection efforts, with a democratic and decentralized system of governance. Just 27 days later, the &lt;a href=&#34;https://psysciacc.org/&#34;&gt;Psychological Science Accelerator&lt;/a&gt; (PSA) was born. Today, over 300 psychology labs from more than 50 countries have voluntarily signed up as members of the network, and several operations and advisory committees are hard at work hammering out our guidelines and operational procedures. We have three research projects in the pipeline so far, and continually send out calls for new project proposals. You do not have to be a member to propose a project to the network, and once projects are accepted, labs from the network volunteer for data collection on each individual project.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://fusiontables.googleusercontent.com/embedviz?q=select+col4+from+1IATtTqIk8ESi6su86_UlIwE9XZ49JDgWMCI-jvkk&amp;amp;viz=MAP&amp;amp;h=false&amp;amp;lat=49.95961088342022&amp;amp;lng=17.430138088922604&amp;amp;t=1&amp;amp;z=4&amp;amp;l=col4&amp;amp;y=2&amp;amp;tmplt=2&amp;amp;hml=ONE_COL_LAT_LNG&#34;&gt;&lt;img src=&#34;/img/PSA_map.png&#34; alt=&#34;PSA network map as of 20-08-2018&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The purpose of the PSA is to provide the manpower necessary to conduct high-quality studies of important research questions in psychology. We aim to address several of the key issues facing psychological research all at once. Every project conducted by the PSA network will be pre-registered, and simultaneously replicated by multiple labs. Projects will be guaranteed a sample size large enough to provide accurate estimates of the effects of interest. Because the network contains labs from all continents, we also have the ability to facilitate culturally diverse sampling by default. In addition to increased and culturally diverse samples, we are bringing together hundreds of scientists with a diverse set of skills, backgrounds and knowledge. Because we can draw on such an immense pool of expertise, we are uniquely able to secure the quality of study designs. we can also distribute tasks that would normally be extremely time-consuming, like the translation of materials into several different languages. The first study the PSA took on, which will test the valence-dominance model of social perception, now has 117 labs from around the world committed to data collection. Study materials are being translated into 22 separate languages, and committees are assisting the lead authors with everything from ethics applications to statistical analysis. Replication. WEIRD samples. Precision. Expertise. The goal is to address them all in one coordinated effort.&lt;/p&gt;
&lt;p&gt;It is hard to accurately describe just how impactful the data from these collaboration projects may turn out to be for psychology. The “Reproducibility Project: Psychology” has ignited discussions of reproducibility throughout and beyond the realm of psychology. The Many Labs projects have done much to nuance these discussions and to enhance our understanding of how psychological effects behave across experiments. Both projects have stimulated a host of innovations in our methods and research practices. In addition, it is usually standard practice for large scale collaborations to make their data freely accessible online. This adds value in at least two ways. First, it respects the principle of transparency in science, and makes it possible for independent researchers to verify any reported results &lt;span class=&#34;citation&#34;&gt;(which can be extremely important. See e.g. Etchells and Chambers 2018)&lt;/span&gt;. Second, it allows independent researchers to reuse the data in novel ways. For example, data from Many Labs 3 have been reanalyzed to provide falsifying tests of ego depletion theory &lt;span class=&#34;citation&#34;&gt;(Vadillo, Gold, and Osman 2018)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The collaborations here mentioned are all fairly recent projects, so we can only speculate what their long term impact on the field will be. However, my hunch is that we are witnessing the early version of what will become a new gold standard for research in psychology. By no means do I think that large scale collaboration projects will be the only research conducted in psychology. These projects are slow moving, inflexible, and resource intensive compared to small scale lab research, and sometimes studies needs to be cheap and flexible. But I do think that large scale collaboration projects will become the most rigorous empirical process we can subject many of our research questions to. As such, I also think the data from these projects will eventually constitute much of the foundation upon which novel psychological theory will build. I therefore heartily recommend checking out the research that is coming out of these projects. They are authoritative reports on the topics they cover, and they have taught me a lot about psychological science in general.&lt;/p&gt;
&lt;p&gt;If you are passionate about psychological research, why not join a collaboration yourself? The Psychological Science Accelerator welcomes members from all walks of academia. Contribution is voluntary, and level of contribution is completely up to you. At our website you can find a link to &lt;a href=&#34;https://psysciacc.org/get-involved/&#34;&gt;our sign-up form&lt;/a&gt;. We need help with everything from reviewing incoming project proposals, to feedback on policy, to data collection. I’m unfortunately not sure how other projects handle lab recruitment at the time of writing. If you do, let me know in the comment section!&lt;/p&gt;
&lt;p&gt;I suppose the deeper reason why I see large scale collaboration as a solution to current issues is that I believe science is a fundamentally collaborative effort. If you share your discovery, we all make the discovery. If you share your knowledge, we all become knowledgeable. Ambition, prestige and a competitive spirit may drive individual scientists to do great things, but there would be no moon landing, no human genome project, no penicillin, no internet, if not for the ability of all scientists to work together in a common pursuit of knowledge.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;acknowledgements&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;This is a shortened, translated version of an article to be published in “Psykologisk tidsskrift NTNU”, a pscyhology magazine run by students at the Norwegian University of Science and Technology. Thanks to Gerit Phul for providing feedback on the english version of the manuscript.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Camerer2016&#34;&gt;
&lt;p&gt;Camerer, Colin F., Anna Dreber, Eskil Forsell, Teck-Hua Ho, Jürgen Huber, Magnus Johannesson, Michael Kirchler, et al. 2016. “Evaluating Replicability of Laboratory Experiments in Economics.” &lt;em&gt;Science&lt;/em&gt;, March, aaf0918. doi:&lt;a href=&#34;https://doi.org/10.1126/science.aaf0918&#34;&gt;10.1126/science.aaf0918&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Camerer2018&#34;&gt;
&lt;p&gt;Camerer, Colin F., Anna Dreber, Felix Holzmeister, Teck-Hua Ho, Jürgen Huber, Magnus Johannesson, Michael Kirchler, et al. 2018. “Evaluating the Replicability of Social Science Experiments in Nature and Science Between 2010 and 2015.” &lt;em&gt;Nature Human Behaviour&lt;/em&gt;, August, 1. doi:&lt;a href=&#34;https://doi.org/10.1038/s41562-018-0399-z&#34;&gt;10.1038/s41562-018-0399-z&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Cova2018&#34;&gt;
&lt;p&gt;Cova, Florian, Brent Strickland, Angela Abatista, Aurélien Allard, James Andow, Mario Attie, James Beebe, et al. 2018. “Estimating the Reproducibility of Experimental Philosophy.” &lt;em&gt;Review of Philosophy and Psychology&lt;/em&gt;, June. doi:&lt;a href=&#34;https://doi.org/10.1007/s13164-018-0400-9&#34;&gt;10.1007/s13164-018-0400-9&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Ebersole2016&#34;&gt;
&lt;p&gt;Ebersole, Charles R., Olivia E. Atherton, Aimee L. Belanger, Hayley M. Skulborstad, Jill M. Allen, Jonathan B. Banks, Erica Baranski, et al. 2016. “Many Labs 3: Evaluating Participant Pool Quality Across the Academic Semester via Replication.” &lt;em&gt;Journal of Experimental Social Psychology&lt;/em&gt; 67 (November): 68–82. doi:&lt;a href=&#34;https://doi.org/10.1016/j.jesp.2015.10.012&#34;&gt;10.1016/j.jesp.2015.10.012&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-zotero-1577&#34;&gt;
&lt;p&gt;“Effort to Reproduce Cancer Studies Scales down to 18 Papers.” n.d. &lt;em&gt;The Scientist Magazine&lt;/em&gt;. https://www.the-scientist.com/news-opinion/effort-to-reproduce-cancer-studies-scales-down-effort-to-18-papers-64593.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Etchells2018&#34;&gt;
&lt;p&gt;Etchells, Pete, and Chris Chambers. 2018. “Mindless Eating: Is There Something Rotten Behind the Research?” &lt;em&gt;The Guardian&lt;/em&gt;, February.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-2018b&#34;&gt;
&lt;p&gt;“Large Hadron Collider.” 2018. &lt;em&gt;Wikipedia&lt;/em&gt;, August.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-OpenScienceCollaboration2015&#34;&gt;
&lt;p&gt;Open Science Collaboration. 2015. “Estimating the Reproducibility of Psychological Science.” &lt;em&gt;Science&lt;/em&gt; 349 (6251): aac4716–aac4716. doi:&lt;a href=&#34;https://doi.org/10.1126/science.aac4716&#34;&gt;10.1126/science.aac4716&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-zotero-1543&#34;&gt;
&lt;p&gt;“The ManyBabies Project.” n.d. &lt;em&gt;Manybabies.github.io&lt;/em&gt;. https://manybabies.github.io/.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Vadillo2018&#34;&gt;
&lt;p&gt;Vadillo, Miguel A., Natalie Gold, and Magda Osman. 2018. “Searching for the Bottom of the Ego Well: Failure to Uncover Ego Depletion in Many Labs 3.” &lt;em&gt;Royal Society Open Science&lt;/em&gt; 5 (8): 180390. doi:&lt;a href=&#34;https://doi.org/10.1098/rsos.180390&#34;&gt;10.1098/rsos.180390&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>What to Replicate?</title>
      <link>/post/what-to-replicate/</link>
      <pubDate>Sat, 09 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/what-to-replicate/</guid>
      <description>&lt;div id=&#34;justifications-of-study-choice-from-85-replication-studies.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Justifications of study choice from 85 replication studies.&lt;/h2&gt;
&lt;p&gt;&lt;br/&gt; In their recent BBS article, &lt;span class=&#34;citation&#34;&gt;Zwaan et al. (2017)&lt;/span&gt; synthesized arguments for and against replication research and laid out a convincing argument for the value of direct replication in science. My collaborators and I wrote a commentary on this article &lt;span class=&#34;citation&#34;&gt;(Coles et al. 2018)&lt;/span&gt;. In it, we argued that in order to maximize the utility of replication in a science that is operating under resource constraints (there is only so much time and money for doing research), we need to deal with the question of when to replicate. In other words, assume that a researcher has limited resources and can either replicate a previous study or run an original study of their own. Both of these options have costs (e.g. money for subject recruitment, time spent conducting the study) and benefits (e.g. theoretical innovation, estimate accuracy, societal impact). Considering both options, the researcher will need to decide which has the higher cost/benefit ratio.&lt;/p&gt;
&lt;p&gt;In a another project I am working on for the Open Science Collaboration, we are trying to develop some formalized tools to help researchers justify their decisions of which studies to replicate. We make the assumption that every researcher has to make decisions under resource constraints, and we assume that they have already decided to conduct a replication. They now face a new problem: There are many original findings that they could replicate. Which one should they choose? We may all agree with Zwaan et al. (2017) that “the idea that observations can be recreated and verified by independent sources is usually seen as a bright line of demarcation that separates science from non-science”, but that does not really help us prioritize which observations to recreate. What makes a study more valuable to replicate than another?&lt;/p&gt;
&lt;p&gt;In the process of coming up with answers to this question, I thought it would be useful to take a look at how researchers “in the wild” justify their replication efforts. They must have some reason for choosing a specific study to replicate, and it seems reasonable to assume that authors would provide these reasons in their report. So I went to the “Curated Replications” dataset at &lt;a href=&#34;http://curatescience.org&#34;&gt;curatescience.org&lt;/a&gt; and started working my way through the links in the table. Eighty-five papers later, here are my takeaways.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;replication-justifications&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Replication Justifications&lt;/h1&gt;
&lt;p&gt;Based on my reading of and subjective judgement of similarity between the justifications for study selection mentioned in the 85 replication reports, I have grouped them into five major categories: theoretical impact, personal interest, academic impact, public/social impact, and methodological concerns. For each category I have included a short description, and a few illustrative quotes with a reference to the quoted articles in each case. It should be noted that any given replication will usually deploy more than one justification for why a finding was considered valuable to replicate, often drawing from several different categories. At the end of this article you can find a link to a spreadsheet containing the justification quotes I have based my review on, as well as article DOIs, for almost all of the 85 reports reviewed (some reports did not have a justification and/or DOI).&lt;/p&gt;
&lt;div id=&#34;theoretical-impact&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;strong&gt;Theoretical impact&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;One of the most widely deployed justifications for replication is arguing for the theoretical significance of the finding. These arguments are sometimes quite specific:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: &lt;span class=&#34;citation&#34;&gt;IJzerman et al. (2014)&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“This latter effect [age*gender interaction] is an important component of the theory that sexual jealousy is evolutionarily prepared, as the theory predicts sex differences for both age groups…”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Other times justifications are more general. They might simply state that the original finding has generated a lot of novel research, or that it has been important for theorizing within the field:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: &lt;span class=&#34;citation&#34;&gt;Cheung et al. (2016)&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“This highly cited paper serves as a cornerstone for the theoretical importance of relationship commitment as a predictor of relationship outcomes, including forgiveness. The findings have important implications for the theoretical understanding of forgiveness…”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;personal-interest&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;strong&gt;Personal interest&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Similar to theoretical impact, though harder to nail down in a specific quote, personal interest represents the author’s own interest in the topic they are studying. A large portion of replications I reviewed were phrased in such a way that the authors seemed partially motivated by their own personal interest in the topic at hand. Some illustrative cases are found in conceptual replications, where the replication itself is often a stepping stone on the way to what the authors really care about: extending current research paradigms.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: &lt;span class=&#34;citation&#34;&gt;Ronay et al. (2017)&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“The goal of the current research was twofold. First, we intended to replicate Carney et al.’s (2010) main effects and to test the possibility that the relationship between embodied power and risk-taking is statistically mediated by increases in testosterone… Our second goal was to test the possibility that elevated levels of testosterone increase overconfidence, which in turn may facilitate risk-taking…”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;academic-impact&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;strong&gt;Academic impact&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Another common justification for choosing a finding to replicate is to refer to the academic impact of either the original finding or the paper it is reported in. There are many indicators of academic impact researchers can use, some more quantifiable than others, but all are related in some way to the standing of the paper among scientists in the field. Examples of less quantifiable justifications include the following:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example (generative finding)&lt;/strong&gt;: &lt;span class=&#34;citation&#34;&gt;Lynott et al. (2014)&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“The [original] findings… has impacted subsequent research investigating how experiences of hot and cold can prime other behaviors…”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example(textbook case)&lt;/strong&gt;: &lt;span class=&#34;citation&#34;&gt;Vermeulen et al. (2014)&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“Moreover, the study appears in nearly every student textbook on persuasion and consumer psychology (e.g., Cialdini, 2001; Fennis &amp;amp; Stroebe, 2010; Peck &amp;amp; Childers, 2008; Saad, 2007)…”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example (“classic” study)&lt;/strong&gt;: &lt;span class=&#34;citation&#34;&gt;Wesselmann et al. (2014)&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“Schachter’s groundbreaking demonstration of the deviation-rejection link has captivated social psychologists for decades. The findings and paradigm were so compelling that the deviation-rejection link is often taken for granted and sometimes may be misrepresented…”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A more quantifiable approach is to quote the citation impact of the original study in question. In these cases it is often common to state the date and source of the citation number as well. Though often used, it is not apparent what constitutes a “widely cited” article. In the 85 articles reviewed here, quoted numbers range from 21 to over 1600. To provide a reference point for these numbers, I acquired the Crossref citation counts for 2854 empirical papers from the psychology literature. These papers are part of a dataset of psychological effects reported in meta-analyses, which is currently being curated by our lab. Median citation count was 29. Citation frequencies are plotted in Figure 1.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example (citation count)&lt;/strong&gt;: &lt;span class=&#34;citation&#34;&gt;Harris et al. (2013)&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“Because the paper has been cited well over 1100 times, an attempt to replicate its findings would seem warranted…”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:figs&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/post/2018-06-09-what-to-replicate_files/figure-html/figs-1.png&#34; alt=&#34;Histogram of Crossref citation counts for 2854 empirical research papers from the psychological literature. The black vertical line represents the median of the distribution. 1.7% of papers were cited more than 400 times. For visual purposes, these are not displayed.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Histogram of Crossref citation counts for 2854 empirical research papers from the psychological literature. The black vertical line represents the median of the distribution. 1.7% of papers were cited more than 400 times. For visual purposes, these are not displayed.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;publicsocietal-impact&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;strong&gt;Public/societal impact&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Somewhat less common are appeals to the public or societal impact of a finding. This can refer to mentions of the finding in the popular press, bringing up altmetrics-related numbers, practical use cases of the findings such as in therapy or in court cases, or the public policy informed by a particular finding. The three examples listed below are just a sample of the justifications deployed in the literature:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example (public impact)&lt;/strong&gt;: &lt;span class=&#34;citation&#34;&gt;Connors et al. (2016)&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“This research was also featured in such premiere outlets as Scientific American Mind, The Financial Times, The Wall Street Journal, The Huffington Post, NBC News and The Globe and Mail…”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example (policy)&lt;/strong&gt;: &lt;span class=&#34;citation&#34;&gt;Mcarthy et al. (2016)&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“The 10 Commandments study also has political implications: It was cited as a critical building block of self-concept maintenance theory in a set of policy recommendations made to President Obama as part of the REVISE model (Shahar, Gino, Barkan, &amp;amp; Ariely, 2015)…”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example: (practical implementation)&lt;/strong&gt;: &lt;span class=&#34;citation&#34;&gt;Pashler, Rohrer, and Harris (2013)&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“If this effect is robust, it would seem to have considerable potential impact in practical areas. Collection of self-report data from people is a commonplace and costly activity in domains ranging from marketing research to public health and opinion polling. A very low-cost method of increasing candor from respondents would have major significance…”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;methodological-concerns&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;strong&gt;Methodological concerns&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The umbrella term “methodological concerns” covers perhaps the largest range of qualitatively different justifications. However, they share a fundamental similarity: they all express some doubt in the conclusions of the original research.&lt;/p&gt;
&lt;p&gt;The reason for doubt varies. In some cases, original estimates of quantities are just not very precise, and researchers may express a desire to increase the accuracy, or narrow the confidence intervals, of a given estimate. In other cases, there may be reasons to believe that the original estimates cannot be trusted due to failures to replicate conceptually similar findings, due to contradicting findings in the existing literature, or the replicating researcher may suspect that questionable research practices (QRPs) or publication bias is biasing the reported numbers. I have not seen these concerns directed towards the the original study authors personally, but replicating authors might refer to widespread problems with QRPs in general. For example, they might express suspicion based on the general tendency for effect sizes in psychology to be overestimated. Finally, replicating authors may simply point out that few or no direct replications of the original finding exist, and/or that the original authors have called for replication of their own findings. The examples listed below do not capture the full nuance of justifications based on methodological concerns. I refer the interested reader to the spreadsheet for more cases.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example (imprecise estimate)&lt;/strong&gt;: &lt;span class=&#34;citation&#34;&gt;Donnellan, Lucas, and Cesario (2015)&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“We undertook this [replication] effort for at least three reasons… First and foremost, the original studies were based on small samples (n = 51 and n = 41) and therefore they generated effect size estimates with relatively wide confidence intervals…”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example (QRPs)&lt;/strong&gt;: &lt;span class=&#34;citation&#34;&gt;Harris et al. (2013)&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“it seems at least possible that the social and goal priming literature might contain many large observed effects due to numerous false alarms. This could occur if a great number of small underpowered experiments have been conducted, with only those results reaching significance having been published…”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example (lack of replications)&lt;/strong&gt;: &lt;span class=&#34;citation&#34;&gt;Cheung et al. (2016)&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“No direct replications of [the original] study have been published. This RRR is designed to provide a direct replication of this influential finding and to provide a more precise estimate of the size of the effect…”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example (Existing evidence is equivocal)&lt;/strong&gt;: &lt;span class=&#34;citation&#34;&gt;H. C. Sinclair, Hood, and Wright (2014)&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“Since the original study, replications of the effect have been elusive… Few studies find support for anything approximating the effect. Instead, most find the ‘‘social network effect’’ whereby disapproval from one’s social network – whether family or friends – leads to declines in romantic relationship quality… A limitation of the counterevidence for the Romeo and Juliet effect is the fact that none of the follow-up studies used the original scales.”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;large-scale-collaborations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;strong&gt;Large Scale Collaborations&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;A discussion of replication justifications would not be complete without considering how the large scale lab replication collaborations like Many Labs and the Reproducibility Projects justify their sampling procedures. These are special cases in at least three ways.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The authors are often interested in introducing some element of randomness into the study selection process in order to get a more representative sample from the population of effects in the literature.&lt;/li&gt;
&lt;li&gt;Because of the sheer volume of replication efforts to be undertaken, practical constraints such as the length of the experimental design become an issue.&lt;/li&gt;
&lt;li&gt;Because they are all preregistered, and original study selection is part of their sampling procedure, justifications are usually more elaborate than for the average replication study.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The exact justification text varies somewhat from project to project. It is however interesting to note that academic impact features in the justification process for almost all of these large scale projects. I refer the reader to the spreadsheet for details of each collaboration’s justifications.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;caveats-summary&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;strong&gt;Caveats &amp;amp; Summary&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;I do want to highlight some caveats of this project. First and foremost, I did not apply formal qualitative methods to this literature search, nor did I comprehensively comb through the literature to make sure I discovered every available justification out there. I am sure that there are more examples of justifications in studies I did not review. In fact, I am pretty sure there are justifications in the papers I did review that I might have missed. Second, as was pointed out to me by a colleague, there is no guarantee that the justifications that authors put down in their papers are the real reasons for why they choose this studyover that study. If researchers sometimes rewrite the introduction section of their original research papers to spice up the importance of their work, they might also do this when writing replication-research papers. For example, the researchers could have been motivated purely by strong personal doubts in an effect, but might choose to refer to the citations of the original work because this seems more objective. Finally, the overwhelming majority of the replication reports reviewed here are from psychological science, and scholars in other fields of science may of course have widely differing justifications for conducting replications. Consider this a non-representative sample of possible justifications. If you think I have missed important justifications, or mischaracterized the intentions of any author mentioned here, let me know!&lt;/p&gt;
&lt;p&gt;In the paper I am working on, I hope to elaborate more on how researchers could formalize some of these justifications by specifying formulas for replication value. Until then, I hope this will serve as a useful starting point if you are looking to do replication research, and are curious about how researchers go about justifying which finding to replicate.&lt;/p&gt;
&lt;p&gt;Happy replicating!&lt;/p&gt;
&lt;div id=&#34;updates&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Updates&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A registered and citeable version of this blog post, including a copy of the linked spreadsheet, is available at &lt;a href=&#34;https://doi.org/10.5281/zenodo.1286715&#34; class=&#34;uri&#34;&gt;https://doi.org/10.5281/zenodo.1286715&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;spreadsheet-of-justifications&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Spreadsheet of Justifications&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.google.com/spreadsheets/d/1HzBePXvDAeGu8ND04E18u7BynT75LgW4vcLFNDUn7GU/edit?usp=sharing&#34; class=&#34;uri&#34;&gt;https://docs.google.com/spreadsheets/d/1HzBePXvDAeGu8ND04E18u7BynT75LgW4vcLFNDUn7GU/edit?usp=sharing&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The spreadsheet include quotes from the 85 papers reviewed for this piece. Please note the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Three dots (…) signal that text has been skipped.&lt;/li&gt;
&lt;li&gt;Square brackets [] signal paraphrasing.&lt;/li&gt;
&lt;li&gt;Cells in the “DOI” column are listed as NA when a DOI could not be obtained.&lt;/li&gt;
&lt;li&gt;Cells “Replication Justifications” column are listed as NA when no discernable justification for the replication could be derived from either the introduction or discussion section of the manuscript.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;acknowledgements&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Acknowledgements&lt;/h3&gt;
&lt;p&gt;Thanks to &lt;a href=&#34;https://twitter.com/coles_nicholas_&#34;&gt;Nicholas Coles&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/chrisharms&#34;&gt;Christopher Harms&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/lakens&#34;&gt;Daniël Lakens&lt;/a&gt;, and &lt;a href=&#34;https://twitter.com/LeonidTiokhin&#34;&gt;Leonid Tiokhin&lt;/a&gt; for helpful comments and suggestions on drafts for this post. Thanks to &lt;a href=&#34;https://twitter.com/eplebel&#34;&gt;Etienne LeBel&lt;/a&gt; for curating the dataset used for this post and making it freely available online. Thanks to &lt;a href=&#34;https://twitter.com/hardsci&#34;&gt;Sanjay Srivastava&lt;/a&gt; for making me aware of some recent replications not included in the CurateScience dataset.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Cheung2016&#34;&gt;
&lt;p&gt;Cheung, I., L. Campbell, E. P. LeBel, R. A. Ackerman, B. Aykutoğlu, š. Bahník, J. D. Bowen, et al. 2016. “Registered Replication Report: Study 1 from Finkel, Rusbult, Kumashiro, &amp;amp; Hannon (2002).” &lt;em&gt;Perspectives on Psychological Science&lt;/em&gt; 11 (5): 750–64. doi:&lt;a href=&#34;https://doi.org/10.1177/1745691616664694&#34;&gt;10.1177/1745691616664694&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Coles2018&#34;&gt;
&lt;p&gt;Coles, Nicholas, Leonid Tiokhin, Anne Scheel, Peder Isager, and Daniel Lakens. 2018. “The Costs and Benefits of Replication Studies.” doi:&lt;a href=&#34;https://doi.org/10.17605/osf.io/c8akj&#34;&gt;10.17605/osf.io/c8akj&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Connors2016&#34;&gt;
&lt;p&gt;Connors, Scott, Mansur Khamitov, Sarah Moroz, Lorne Campbell, and Claire Henderson. 2016. “Time, Money, and Happiness: Does Putting a Price on Time Affect Our Ability to Smell the Roses?” &lt;em&gt;Journal of Experimental Social Psychology&lt;/em&gt; 67 (November): 60–64. doi:&lt;a href=&#34;https://doi.org/10.1016/j.jesp.2015.08.005&#34;&gt;10.1016/j.jesp.2015.08.005&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Donnellan2015&#34;&gt;
&lt;p&gt;Donnellan, M. Brent, Richard E. Lucas, and Joseph Cesario. 2015. “On the Association Between Loneliness and Bathing Habits: Nine Replications of Bargh and Shalev (2012) Study 1.” &lt;em&gt;Emotion&lt;/em&gt; 15 (1): 109–19. doi:&lt;a href=&#34;https://doi.org/10.1037/a0036079&#34;&gt;10.1037/a0036079&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Harris2013&#34;&gt;
&lt;p&gt;Harris, Christine R., Noriko Coburn, Doug Rohrer, and Harold Pashler. 2013. “Two Failures to Replicate High-Performance-Goal Priming Effects.” Edited by Jan de Fockert. &lt;em&gt;PLoS ONE&lt;/em&gt; 8 (8): e72467. doi:&lt;a href=&#34;https://doi.org/10.1371/journal.pone.0072467&#34;&gt;10.1371/journal.pone.0072467&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-IJzerman2014&#34;&gt;
&lt;p&gt;IJzerman, Hans, Irene Blanken, Mark J. Brandt, J. M. Oerlemans, Marloes M. W. Van den Hoogenhof, Stephanie J. M. Franken, and Mathe W. G. Oerlemans. 2014. “Sex Differences in Distress from Infidelity in Early Adulthood and in Later Life: A Replication and Meta-Analysis of Shackelford et Al. (2004).” &lt;em&gt;Social Psychology&lt;/em&gt; 45 (3): 202–8. doi:&lt;a href=&#34;https://doi.org/10.1027/1864-9335/a000185&#34;&gt;10.1027/1864-9335/a000185&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Lynott2014&#34;&gt;
&lt;p&gt;Lynott, Dermot, Katherine S. Corker, Jessica Wortman, Louise Connell, M. Brent Donnellan, Richard E. Lucas, and Kerry O’Brien. 2014. “Replication of ‘Experiencing Physical Warmth Promotes Interpersonal Warmth’ by Williams and Bargh (2008).” &lt;em&gt;Social Psychology&lt;/em&gt; 45 (3): 216–22. doi:&lt;a href=&#34;https://doi.org/10.1027/1864-9335/a000187&#34;&gt;10.1027/1864-9335/a000187&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Mcarthy2016&#34;&gt;
&lt;p&gt;Mcarthy, Randy, John Skowronski, Bruno Verschuere, Ewout Meijer, Jim Ariane, Katherine Hoogesteyn, and Robin Orthey. 2016. “Registered Replication Report: Srull &amp;amp; Wyer (1979).” https://osf.io/29xv5/.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Pashler2013&#34;&gt;
&lt;p&gt;Pashler, Harold, Doug Rohrer, and Christine R. Harris. 2013. “Can the Goal of Honesty Be Primed?” &lt;em&gt;Journal of Experimental Social Psychology&lt;/em&gt; 49 (6): 959–64. doi:&lt;a href=&#34;https://doi.org/10.1016/j.jesp.2013.05.011&#34;&gt;10.1016/j.jesp.2013.05.011&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Ronay2017&#34;&gt;
&lt;p&gt;Ronay, Richard, Joshua M. Tybur, Dian van Huijstee, and Margot Morssinkhof. 2017. “Embodied Power, Testosterone, and Overconfidence as a Causal Pathway to Risk-Taking.” &lt;em&gt;Comprehensive Results in Social Psychology&lt;/em&gt; 2 (1): 28–43. doi:&lt;a href=&#34;https://doi.org/10.1080/23743603.2016.1248081&#34;&gt;10.1080/23743603.2016.1248081&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Sinclair2014&#34;&gt;
&lt;p&gt;Sinclair, H. Colleen, Kristina B. Hood, and Brittany L. Wright. 2014. “Revisiting the Romeo and Juliet Effect (Driscoll, Davis, &amp;amp; Lipetz, 1972): Reexamining the Links Between Social Network Opinions and Romantic Relationship Outcomes.” &lt;em&gt;Social Psychology&lt;/em&gt; 45 (3): 170–78. doi:&lt;a href=&#34;https://doi.org/10.1027/1864-9335/a000181&#34;&gt;10.1027/1864-9335/a000181&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Vermeulen2014&#34;&gt;
&lt;p&gt;Vermeulen, Ivar, Anika Batenburg, Camiel J. Beukeboom, and Tim Smits. 2014. “Breakthrough or One-Hit Wonder?: Three Attempts to Replicate Single-Exposure Musical Conditioning Effects on Choice Behavior (Gorn, 1982).” &lt;em&gt;Social Psychology&lt;/em&gt; 45 (3): 179–86. doi:&lt;a href=&#34;https://doi.org/10.1027/1864-9335/a000182&#34;&gt;10.1027/1864-9335/a000182&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Wesselmann2014&#34;&gt;
&lt;p&gt;Wesselmann, Eric D., Kipling D. Williams, John B. Pryor, Fredrick A. Eichler, Devin M. Gill, and John D. Hogue. 2014. “Revisiting Schachter’s Research on Rejection, Deviance, and Communication (1951).” &lt;em&gt;Social Psychology&lt;/em&gt; 45 (3): 164–69. doi:&lt;a href=&#34;https://doi.org/10.1027/1864-9335/a000180&#34;&gt;10.1027/1864-9335/a000180&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Zwaan2017&#34;&gt;
&lt;p&gt;Zwaan, Rolf A., Alexander Etz, Richard E. Lucas, and M. Brent Donnellan. 2017. “Making Replication Mainstream.” &lt;em&gt;Behavioral and Brain Sciences&lt;/em&gt;, October, 1–50. doi:&lt;a href=&#34;https://doi.org/10.1017/S0140525X17001972&#34;&gt;10.1017/S0140525X17001972&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>/talk/example-talk/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0100</pubDate>
      
      <guid>/talk/example-talk/</guid>
      <description>&lt;p&gt;Embed your slides or video here using &lt;a href=&#34;https://sourcethemes.com/academic/post/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;. Further details can easily be added using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>/project/deep-learning/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>/project/deep-learning/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;

&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;

&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;

&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;

&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>/project/example-external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>/project/example-external-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Person Re-Identification System For Mobile Devices</title>
      <link>/publication/person-re-identification/</link>
      <pubDate>Tue, 01 Sep 2015 00:00:00 +0200</pubDate>
      
      <guid>/publication/person-re-identification/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mobile visual clothing search</title>
      <link>/publication/clothing-search/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 +0200</pubDate>
      
      <guid>/publication/clothing-search/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
